{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import Resize, ToPILImage, GaussianBlur\n",
    "from torchvision.transforms._functional_tensor import _get_gaussian_kernel2d\n",
    "from torchvision.io import read_image\n",
    "from diffusers.pipelines import ScoreSdeVePipeline\n",
    "from diffusers.utils.torch_utils import randn_tensor\n",
    "from diffusers.pipelines.pipeline_utils import ImagePipelineOutput\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'     # Update this line if you want to use a different device such as TPU or Macbook's MPS\n",
    "PRETRAINED = \"google/ncsnpp-celebahq-256\"\n",
    "TEST_IMAGE = \"test_celabhq.png\"\n",
    "N_INFERENCE_STEPS = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "unconditional_pipeline = ScoreSdeVePipeline.from_pretrained(PRETRAINED).to(device=DEVICE)\n",
    "resize = Resize(256)\n",
    "test_img = read_image(TEST_IMAGE)\n",
    "test_img = resize(test_img) / 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities\n",
    "\n",
    "def show_img(img, size = 3) -> None:\n",
    "    plt.figure(figsize=(size, size))\n",
    "    plt.imshow(img.squeeze().permute(-2,-1,-3))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "tensor_to_PIL = ToPILImage()\n",
    "\n",
    "\n",
    "class TractableInversePipeline(ScoreSdeVePipeline):\n",
    "\n",
    "    def add_conditional_gradient(self, sample, output, y, sigma):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def __call__(\n",
    "        self,\n",
    "        y,\n",
    "        batch_size: int = 1,\n",
    "        num_inference_steps: int = 2000,\n",
    "        generator: Optional[Union[torch.Generator, List[torch.Generator]]] = None,\n",
    "        output_type: Optional[str] = \"pil\",\n",
    "        return_dict: bool = True,\n",
    "        debug: bool = False,\n",
    "        **kwargs,\n",
    "    ) -> Union[ImagePipelineOutput, Tuple]:\n",
    "        img_size = self.unet.config.sample_size\n",
    "        shape = (batch_size, 3, img_size, img_size)\n",
    "\n",
    "        model = self.unet\n",
    "\n",
    "        sample = randn_tensor(shape, generator=generator) * self.scheduler.init_noise_sigma\n",
    "        sample = sample.to(self.device)\n",
    "\n",
    "        self.scheduler.set_timesteps(num_inference_steps)\n",
    "        self.scheduler.set_sigmas(num_inference_steps)\n",
    "\n",
    "        for i, t in enumerate(self.progress_bar(self.scheduler.timesteps)):\n",
    "            sigma_t = self.scheduler.sigmas[i] * torch.ones(shape[0], device=self.device)\n",
    "\n",
    "            # correction step\n",
    "            for _ in range(self.scheduler.config.correct_steps):\n",
    "                model_output = self.unet(sample, sigma_t).sample\n",
    "                model_output = self.add_conditional_gradient(sample, model_output, y, sigma_t)\n",
    "                sample = self.scheduler.step_correct(model_output, sample, generator=generator).prev_sample\n",
    "\n",
    "            # prediction step\n",
    "            model_output = model(sample, sigma_t).sample\n",
    "            model_output =  self.add_conditional_gradient(sample, model_output, y, sigma_t)\n",
    "            output = self.scheduler.step_pred(model_output, t, sample, generator=generator)\n",
    "\n",
    "            sample, sample_mean = output.prev_sample, output.prev_sample_mean\n",
    "\n",
    "            if i % 500 == 0 and debug:\n",
    "                show_img(sample[0].cpu())\n",
    "\n",
    "        sample = sample_mean.clamp(0, 1)\n",
    "        sample = sample.cpu().permute(0, 2, 3, 1).numpy()\n",
    "        if output_type == \"pil\":\n",
    "            sample = self.numpy_to_pil(sample)\n",
    "\n",
    "        if not return_dict:\n",
    "            return (sample,)\n",
    "\n",
    "        return ImagePipelineOutput(images=sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperResolutionPipeline(TractableInversePipeline):\n",
    "    \"\"\" Super resolution from a smaller image\n",
    "\n",
    "    Recall from controllable generation we need to find grad(log p(y | x(t))) to add as a conditional gradient\n",
    "    This is directly tractable by pooling x(t), and considering a normal distribution N' from the reference image.\n",
    "\n",
    "    The normal distribution has a variance that can be obtained by considering sums of gaussians, and multiplying\n",
    "    a gaussian by a constant. Both are proportional to the area covered by the downsampling kernel.\n",
    "\n",
    "    N' = (reference, (sigma * KERNEL**2) / (KERNEL**4))\n",
    "    \"\"\"\n",
    "\n",
    "    def add_conditional_gradient(self, sample, output, y, sigma):\n",
    "        y, kernel_size = y\n",
    "        pool = nn.AvgPool2d(kernel_size=kernel_size, stride=kernel_size)\n",
    "        with torch.enable_grad():\n",
    "            sample.requires_grad = True\n",
    "            d_sample = pool(sample)\n",
    "            diff = d_sample - y\n",
    "            sigma = sigma[0] # sigma is the same across batches\n",
    "            sigma = sigma / kernel_size # STD, Not Variance!!\n",
    "            dist = torch.distributions.Normal(0,sigma)\n",
    "            l_p_x_y = dist.log_prob(diff)\n",
    "            l_p_x_y.sum().backward()\n",
    "            output += sample.grad\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution\n",
    "KERNEL_SIZE = 16\n",
    "\n",
    "pool = nn.AvgPool2d(kernel_size=KERNEL_SIZE, stride=KERNEL_SIZE)\n",
    "downsampled_img = pool(test_img).to(device=DEVICE)\n",
    "plt.axis('off')\n",
    "plt.gcf().set_size_inches(3,3)\n",
    "plt.imshow(downsampled_img.cpu().permute(-2,-1,-3))\n",
    "\n",
    "pipeline = SuperResolutionPipeline(unconditional_pipeline.unet, unconditional_pipeline.scheduler)\n",
    "images = pipeline((downsampled_img, KERNEL_SIZE), batch_size=3, target=False, num_inference_steps=1000).images\n",
    "display(\"Original\", tensor_to_PIL(test_img), \"Generated\", *images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(image_tensor: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.mean(image_tensor, dim=1, keepdims=True).repeat(1, 3, 1, 1)\n",
    "\n",
    "class ColorisationPipeline(TractableInversePipeline):\n",
    "    \"\"\" Colorisation\n",
    "    \"\"\"\n",
    "    def add_conditional_gradient(self, sample, output, y, sigma):\n",
    "        with torch.enable_grad():\n",
    "            sample.requires_grad = True\n",
    "            gray_sample = grayscale(sample)\n",
    "            diff = gray_sample[:, 0] - y[0][0].expand(3, 256, 256)\n",
    "            sigma = sigma[0] # sigma is the same across batches\n",
    "            sigma = sigma / 3.0**0.5 # STD, Not Variance!!\n",
    "            dist = torch.distributions.Normal(0,sigma)\n",
    "            l_p_x_y = dist.log_prob(diff)\n",
    "            l_p_x_y.sum().backward()\n",
    "            output += sample.grad\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = grayscale(test_img.unsqueeze(0)).to(device=DEVICE)\n",
    "pipeline = ColorisationPipeline(unconditional_pipeline.unet, unconditional_pipeline.scheduler)\n",
    "images = pipeline(gray, batch_size=3, target=False, num_inference_steps=1000).images\n",
    "display(\"Original\", tensor_to_PIL(test_img), \"Generated\", *images, tensor_to_PIL(gray.squeeze()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLUR_KERNEL_SIZE = 27\n",
    "gaussian_blur = GaussianBlur(BLUR_KERNEL_SIZE, sigma=2)\n",
    "\n",
    "class DeblurringPipeline(TractableInversePipeline):\n",
    "    \"\"\" Deblurring\n",
    "    \"\"\"\n",
    "    def add_conditional_gradient(self, sample, output, y, sigma):\n",
    "        with torch.enable_grad():\n",
    "            sample.requires_grad = True\n",
    "            blurred_sample = gaussian_blur(sample)\n",
    "            diff = y - blurred_sample\n",
    "            sigma = sigma[0]\n",
    "            dist = torch.distributions.Normal(0,sigma)\n",
    "            l_p_x_y = dist.log_prob(diff)\n",
    "            l_p_x_y.sum().backward()\n",
    "            output += sample.grad\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred = gaussian_blur(test_img).to(device=DEVICE)\n",
    "pipeline = DeblurringPipeline(unconditional_pipeline.unet, unconditional_pipeline.scheduler)\n",
    "images = pipeline(blurred, batch_size=1, target=False, num_inference_steps=1000).images\n",
    "display(\"Original\", tensor_to_PIL(test_img), \"Generated\", *images, tensor_to_PIL(blurred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
