{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import Resize, ToPILImage, GaussianBlur, CenterCrop\n",
    "from torchvision.io import read_image\n",
    "from datasets import load_dataset\n",
    "from diffusers.pipelines import ScoreSdeVePipeline\n",
    "from diffusers.utils.torch_utils import randn_tensor\n",
    "from diffusers.pipelines.pipeline_utils import ImagePipelineOutput\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'     # Update this line if you want to use a different device such as TPU or Macbook's MPS\n",
    "PRETRAINED = \"google/ncsnpp-celebahq-256\"\n",
    "# PRETRAINED = \"google/ncsnpp-church-256\"\n",
    "TEST_IMAGE = \"test_celabhq.png\"\n",
    "# TEST_IMAGE = \"test_lsun_church.png\"\n",
    "TIME_BETWEEN_DEBUG = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset (save test images)\n",
    "\n",
    "DATASET = 'tglcourse/lsun_church_train'\n",
    "dataset = load_dataset(DATASET)\n",
    "dataset['train'][0]['image'].save('test_lsun_church.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "unconditional_pipeline = ScoreSdeVePipeline.from_pretrained(PRETRAINED).to(device=DEVICE)\n",
    "resize = Resize(256)\n",
    "crop = CenterCrop(256)\n",
    "test_img = read_image(TEST_IMAGE)\n",
    "test_img = crop(resize(test_img) / 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities\n",
    "\n",
    "def show_img(img, size = 3) -> None:\n",
    "    plt.figure(figsize=(size, size))\n",
    "    plt.imshow(img.squeeze().permute(-2,-1,-3))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "tensor_to_PIL = ToPILImage()\n",
    "\n",
    "\n",
    "class GradientAdditionPipeline(ScoreSdeVePipeline):\n",
    "\n",
    "    def add_conditional_gradient(self, sample, output, y, sigma):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def __call__(\n",
    "        self,\n",
    "        y,\n",
    "        batch_size: int = 1,\n",
    "        num_inference_steps: int = 2000,\n",
    "        generator: Optional[Union[torch.Generator, List[torch.Generator]]] = None,\n",
    "        output_type: Optional[str] = \"pil\",\n",
    "        return_dict: bool = True,\n",
    "        debug: bool = False,\n",
    "        **kwargs,\n",
    "    ) -> Union[ImagePipelineOutput, Tuple]:\n",
    "        img_size = self.unet.config.sample_size\n",
    "        shape = (batch_size, 3, img_size, img_size)\n",
    "\n",
    "        model = self.unet\n",
    "\n",
    "        sample = randn_tensor(shape, generator=generator) * self.scheduler.init_noise_sigma\n",
    "        sample = sample.to(self.device)\n",
    "\n",
    "        self.scheduler.set_timesteps(num_inference_steps)\n",
    "        self.scheduler.set_sigmas(num_inference_steps)\n",
    "\n",
    "        for i, t in enumerate(self.progress_bar(self.scheduler.timesteps)):\n",
    "            sigma_t = self.scheduler.sigmas[i] * torch.ones(shape[0], device=self.device)\n",
    "\n",
    "            # correction step\n",
    "            for _ in range(self.scheduler.config.correct_steps):\n",
    "                model_output = self.unet(sample, sigma_t).sample\n",
    "                model_output = self.add_conditional_gradient(sample, model_output, y, sigma_t)\n",
    "                sample = self.scheduler.step_correct(model_output, sample, generator=generator).prev_sample\n",
    "\n",
    "            # prediction step\n",
    "            model_output = model(sample, sigma_t).sample\n",
    "            model_output =  self.add_conditional_gradient(sample, model_output, y, sigma_t)\n",
    "            output = self.scheduler.step_pred(model_output, t, sample, generator=generator)\n",
    "\n",
    "            sample, sample_mean = output.prev_sample, output.prev_sample_mean\n",
    "\n",
    "            if i % TIME_BETWEEN_DEBUG == 0 and debug:\n",
    "                show_img(sample[0].cpu())\n",
    "\n",
    "        sample = sample_mean.clamp(0, 1)\n",
    "        sample = sample.cpu().permute(0, 2, 3, 1).numpy()\n",
    "        if output_type == \"pil\":\n",
    "            sample = self.numpy_to_pil(sample)\n",
    "\n",
    "        if not return_dict:\n",
    "            return (sample,)\n",
    "\n",
    "        return ImagePipelineOutput(images=sample)\n",
    "\n",
    "class ConstraintProjectionPipeline(ScoreSdeVePipeline):\n",
    "\n",
    "    def project(self, sample, y, sigma):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def __call__(\n",
    "        self,\n",
    "        y,\n",
    "        batch_size: int = 1,\n",
    "        num_inference_steps: int = 2000,\n",
    "        generator: Optional[Union[torch.Generator, List[torch.Generator]]] = None,\n",
    "        output_type: Optional[str] = \"pil\",\n",
    "        return_dict: bool = True,\n",
    "        debug: bool = False,\n",
    "        **kwargs,\n",
    "    ) -> Union[ImagePipelineOutput, Tuple]:\n",
    "        img_size = self.unet.config.sample_size\n",
    "        shape = (batch_size, 3, img_size, img_size)\n",
    "\n",
    "        model = self.unet\n",
    "\n",
    "        sample = randn_tensor(shape, generator=generator) * self.scheduler.init_noise_sigma\n",
    "        sample = sample.to(self.device)\n",
    "\n",
    "        self.scheduler.set_timesteps(num_inference_steps)\n",
    "        self.scheduler.set_sigmas(num_inference_steps)\n",
    "\n",
    "        upscaled_y = torch.repeat_interleave(y[0], y[1], dim=-2)\n",
    "        upscaled_y = torch.repeat_interleave(upscaled_y, y[1], dim=-1)\n",
    "\n",
    "        for i, t in enumerate(self.progress_bar(self.scheduler.timesteps)):\n",
    "            sigma_t = self.scheduler.sigmas[i] * torch.ones(shape[0], device=self.device)\n",
    "\n",
    "            # correction step\n",
    "            for _ in range(self.scheduler.config.correct_steps):\n",
    "                model_output = self.unet(sample, sigma_t).sample\n",
    "                sample = self.scheduler.step_correct(model_output, sample, generator=generator).prev_sample\n",
    "                sample = self.project(sample, y, self.scheduler.sigmas[i])\n",
    "\n",
    "            # prediction step\n",
    "            model_output = model(sample, sigma_t).sample\n",
    "            output = self.scheduler.step_pred(model_output, t, sample, generator=generator)\n",
    "\n",
    "            sample, sample_mean = output.prev_sample, output.prev_sample_mean\n",
    "\n",
    "            sample = self.project(sample, y, self.scheduler.sigmas[i])\n",
    "\n",
    "            if i % 200 == 0 and debug:\n",
    "                show_img(sample[0].cpu())\n",
    "\n",
    "        sample = sample_mean.clamp(0, 1)\n",
    "        sample = sample.cpu().permute(0, 2, 3, 1).numpy()\n",
    "        if output_type == \"pil\":\n",
    "            sample = self.numpy_to_pil(sample)\n",
    "\n",
    "        if not return_dict:\n",
    "            return (sample,)\n",
    "\n",
    "        return ImagePipelineOutput(images=sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperResolutionPipeline(GradientAdditionPipeline):\n",
    "    def add_conditional_gradient(self, sample, output, y, sigma):\n",
    "        y, kernel_size = y\n",
    "        pool = nn.AvgPool2d(kernel_size=kernel_size, stride=kernel_size)\n",
    "        with torch.enable_grad():\n",
    "            sample.requires_grad = True\n",
    "            d_sample = pool(sample)\n",
    "            diff = d_sample - y\n",
    "            sigma = sigma[0] # sigma is the same across batches\n",
    "            sigma = sigma / kernel_size # STD, Not Variance!!\n",
    "            sigma = sigma\n",
    "            dist = torch.distributions.Normal(0,sigma)\n",
    "            l_p_x_y = dist.log_prob(diff)\n",
    "            l_p_x_y.sum().backward()\n",
    "            # output += sample.grad\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperResolutionProjectionPipeline(ConstraintProjectionPipeline):\n",
    "    def upscale(self, img, kernel_size):\n",
    "        upscaled = torch.repeat_interleave(img, kernel_size, dim=-2)\n",
    "        upscaled = torch.repeat_interleave(upscaled, kernel_size, dim=-1)\n",
    "        return upscaled\n",
    "\n",
    "    def project(self, sample, y, sigma):\n",
    "        y, kernel_size = y\n",
    "        pool = nn.AvgPool2d(kernel_size=kernel_size, stride=kernel_size)\n",
    "        diff = sample - self.upscale(pool(sample), kernel_size)\n",
    "        return self.upscale(y, kernel_size) + diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution\n",
    "KERNEL_SIZE = 16\n",
    "\n",
    "pool = nn.AvgPool2d(kernel_size=KERNEL_SIZE, stride=KERNEL_SIZE)\n",
    "downsampled_img = pool(test_img).to(device=DEVICE)\n",
    "plt.axis('off')\n",
    "plt.gcf().set_size_inches(3,3)\n",
    "plt.imshow(downsampled_img.cpu().permute(-2,-1,-3))\n",
    "\n",
    "#pipeline = SuperResolutionPipeline(unconditional_pipeline.unet, unconditional_pipeline.scheduler)\n",
    "pipeline = SuperResolutionProjectionPipeline(unconditional_pipeline.unet, unconditional_pipeline.scheduler)\n",
    "images = pipeline((downsampled_img, KERNEL_SIZE), batch_size=1, target=False, num_inference_steps=1000, debug=True).images\n",
    "display(\"Original\", tensor_to_PIL(test_img), \"Generated\", *images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manifold Constrained Inpainting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweedie(x_t, score, sigma):\n",
    "  return x_t + score * sigma**2\n",
    "\n",
    "class MCGInpainterPipeline(ScoreSdeVePipeline):\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def __call__(\n",
    "        self,\n",
    "        data: torch.Tensor,\n",
    "        mask: torch.Tensor,\n",
    "        batch_size: int = 1,\n",
    "        num_inference_steps: int = 2000,\n",
    "        generator: Optional[Union[torch.Generator, List[torch.Generator]]] = None,\n",
    "        output_type: Optional[str] = \"pil\",\n",
    "        return_dict: bool = True,\n",
    "        alpha = 1,\n",
    "        mcg = True,\n",
    "        **kwargs,\n",
    "    ) -> Union[ImagePipelineOutput, Tuple]:\n",
    "\n",
    "        img_size = self.unet.config.sample_size\n",
    "        shape = (batch_size, 3, img_size, img_size)\n",
    "\n",
    "        model = self.unet\n",
    "\n",
    "        sample = randn_tensor(shape, generator=generator) * self.scheduler.init_noise_sigma\n",
    "        sample = sample.to(self.device)\n",
    "        # don't need to overwrite initial sample,\n",
    "        # since it should be very noised at the start anyways, due to annealed langevin dynamics\n",
    "        # sample = data * mask + sample * (1. - mask)\n",
    "        # show_img(tensor_to_image(sample))\n",
    "        data = data * mask\n",
    "\n",
    "        self.scheduler.set_timesteps(num_inference_steps)\n",
    "        self.scheduler.set_sigmas(num_inference_steps)\n",
    "\n",
    "        for i, t in enumerate(self.progress_bar(self.scheduler.timesteps)):\n",
    "            sigma_t = self.scheduler.sigmas[i] * torch.ones(shape[0], device=self.device)\n",
    "            std = self.scheduler.sigmas[i]\n",
    "\n",
    "            x_i = sample\n",
    "            # correction step\n",
    "            for _ in range(self.scheduler.config.correct_steps):\n",
    "                model_output = self.unet(sample, sigma_t).sample\n",
    "                sample = self.scheduler.step_correct(model_output, sample, generator=generator).prev_sample\n",
    "\n",
    "                 # Constaint Step\n",
    "                masked_data = data + torch.randn_like(sample) * std\n",
    "                sample = sample * (1. - mask) + masked_data * mask\n",
    "\n",
    "            # prediction step\n",
    "            \n",
    "            model_output = model(sample, sigma_t).sample\n",
    "\n",
    "            output = self.scheduler.step_pred(model_output, t, sample, generator=generator)\n",
    "            sample, sample_mean = output.prev_sample, output.prev_sample_mean\n",
    "\n",
    "            # MCG Step\n",
    "            if mcg:\n",
    "                score = model(x_i, sigma_t).sample\n",
    "                with torch.enable_grad():\n",
    "                    x_i.requires_grad = True\n",
    "                    x_hat = tweedie(x_i, score, std)\n",
    "                    y_hat = mask * x_hat\n",
    "                    dist = (y_hat-data).pow(2)\n",
    "                    dist_norm = torch.sqrt(dist.sum([-1,-2,-3]))\n",
    "                    a = alpha / dist_norm\n",
    "                    dist.sum().backward()\n",
    "                    a = a.reshape((*a.shape, 1, 1, 1))\n",
    "                    sample = sample - a * x_i.grad \n",
    "\n",
    "            # Constaint Step\n",
    "            masked_data = data + torch.randn_like(sample) * std\n",
    "            sample = sample * (1. - mask) + masked_data * mask\n",
    "            sample_mean = sample_mean * (1 - mask) + data * mask\n",
    "\n",
    "\n",
    "        sample = sample_mean.clamp(0, 1)\n",
    "        sample = sample.cpu().permute(0, 2, 3, 1).numpy()\n",
    "        if output_type == \"pil\":\n",
    "            sample = self.numpy_to_pil(sample)\n",
    "\n",
    "        if not return_dict:\n",
    "            return (sample,)\n",
    "\n",
    "        return ImagePipelineOutput(images=sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.ones_like(test_img) \n",
    "size = 80\n",
    "mask[:,128-size:128+size, 128-size: 128+size] = 0\n",
    "masked_img = test_img * mask\n",
    "\n",
    "mask = mask.to(device=DEVICE)\n",
    "masked_img = masked_img.to(device=DEVICE)\n",
    "\n",
    "pipeline = MCGInpainterPipeline(unconditional_pipeline.unet, unconditional_pipeline.scheduler)\n",
    "images = pipeline(masked_img, mask=mask, batch_size=3, target=False, num_inference_steps=1000, mcg=True).images\n",
    "\n",
    "display(*images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(image_tensor: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.mean(image_tensor, dim=1, keepdims=True).repeat(1, 3, 1, 1)\n",
    "\n",
    "class ColorisationPipeline(GradientAdditionPipeline):\n",
    "    \"\"\" Colorisation\n",
    "    \"\"\"\n",
    "    def add_conditional_gradient(self, sample, output, y, sigma):\n",
    "        with torch.enable_grad():\n",
    "            sample.requires_grad = True\n",
    "            gray_sample = grayscale(sample)\n",
    "            diff = gray_sample[:, 0] - y[0][0].expand(3, 256, 256)\n",
    "            sigma = sigma[0] # sigma is the same across batches\n",
    "            sigma = sigma / 3.0**0.5 # STD, Not Variance!!\n",
    "            dist = torch.distributions.Normal(0,sigma)\n",
    "            l_p_x_y = dist.log_prob(diff)\n",
    "            l_p_x_y.sum().backward()\n",
    "            output += sample.grad\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = grayscale(test_img.unsqueeze(0)).to(device=DEVICE)\n",
    "pipeline = ColorisationPipeline(unconditional_pipeline.unet, unconditional_pipeline.scheduler)\n",
    "images = pipeline(gray, batch_size=3, target=False, num_inference_steps=1000).images\n",
    "display(\"Original\", tensor_to_PIL(test_img), \"Generated\", *images, tensor_to_PIL(gray.squeeze()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLUR_KERNEL_SIZE = 27\n",
    "gaussian_blur = GaussianBlur(BLUR_KERNEL_SIZE, sigma=2)\n",
    "\n",
    "class DeblurringPipeline(GradientAdditionPipeline):\n",
    "    \"\"\" Deblurring\n",
    "    \"\"\"\n",
    "    def add_conditional_gradient(self, sample, output, y, sigma):\n",
    "        with torch.enable_grad():\n",
    "            sample.requires_grad = True\n",
    "            blurred_sample = gaussian_blur(sample)\n",
    "            diff = y - blurred_sample\n",
    "            sigma = sigma[0]\n",
    "            dist = torch.distributions.Normal(0,sigma)\n",
    "            l_p_x_y = dist.log_prob(diff)\n",
    "            l_p_x_y.sum().backward()\n",
    "            output += sample.grad\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred = gaussian_blur(test_img).to(device=DEVICE)\n",
    "pipeline = DeblurringPipeline(unconditional_pipeline.unet, unconditional_pipeline.scheduler)\n",
    "images = pipeline(blurred, batch_size=1, target=False, num_inference_steps=1000).images\n",
    "display(\"Original\", tensor_to_PIL(test_img), \"Generated\", *images, tensor_to_PIL(blurred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation (PseudoInverse Guided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tensor_to_PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.eye(3)\n",
    "a[2,2] = 0\n",
    "b = a @ a.T + torch.eye(3)\n",
    "torch.inverse(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
