{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from diffusers import ScoreSdeVePipeline, ScoreSdeVeScheduler, UNet2DModel\n",
    "from diffusers.utils.torch_utils import randn_tensor\n",
    "from diffusers.pipelines.pipeline_utils import ImagePipelineOutput\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from torchvision.models import mobilenet_v3_small, MobileNet_V3_Small_Weights\n",
    "from torchvision.transforms import Resize, PILToTensor, ToPILImage\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from typing import List, Optional, Tuple, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "PRETRAINED = \"google/ncsnpp-celebahq-256\"\n",
    "DATASET_SOURCE = \"Ryan-sjtu/celebahq-caption\"\n",
    "\n",
    "N_INFERENCE_STEPS = 1000\n",
    "BATCH_SIZE = 32\n",
    "N_EPOCHS = 20 \n",
    "NOISE_BATCH = 10 \n",
    "N_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "unconditional_pipeline = ScoreSdeVePipeline.from_pretrained(PRETRAINED).to(device=DEVICE)\n",
    "unconditional_scheduler: ScoreSdeVeScheduler = unconditional_pipeline.scheduler\n",
    "unet = UNet2DModel.from_pretrained(PRETRAINED)\n",
    "dataset: DatasetDict = load_dataset(DATASET_SOURCE)\n",
    "\n",
    "# Demonstrate unconditional generation\n",
    "    # Also helps to set inference steps\n",
    "# example_image = unconditional_pipeline(num_inference_steps=N_INFERENCE_STEPS).images[0]\n",
    "#example_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classifer model\n",
    "\n",
    "class ClassificationNet(nn.Module):\n",
    "    \"\"\"Network for classification based on mobilenet\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_classes: int=2, rff_dim: Optional[int] = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if rff_dim is None:\n",
    "            rff_dim = 0\n",
    "        mobile_net = mobilenet_v3_small(MobileNet_V3_Small_Weights.DEFAULT)\n",
    "        self.cnn = nn.Sequential(\n",
    "            mobile_net.features,\n",
    "            mobile_net.avgpool,\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.2, inplace=True),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features=576 + rff_dim, out_features=64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=64, out_features=n_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # TODO: RFF\n",
    "        x = self.cnn(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = ClassificationNet(n_classes=N_CLASSES).to(device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "train_ds: Dataset = dataset['train'].with_format('torch', device=DEVICE)\n",
    "train_ds = train_ds.map(lambda x: {\n",
    "    'label': \n",
    "        torch.tensor([\n",
    "            1 if 'woman' in x['text'] else 0,\n",
    "            0 if 'woman' in x['text'] else 1\n",
    "        ],\n",
    "        dtype=torch.float32,\n",
    "        device=DEVICE)\n",
    "})\n",
    "dataloader = DataLoader(train_ds, BATCH_SIZE)\n",
    "\n",
    "# Class Weightings\n",
    "weights = torch.zeros((N_CLASSES,)).to(device=DEVICE)\n",
    "for i, data in enumerate(dataloader):\n",
    "    labels = data['label']\n",
    "    weights += torch.sum(labels, dim=0)\n",
    "weights = (sum(weights) / N_CLASSES) / weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "resize = Resize(unconditional_pipeline.unet.config.sample_size)\n",
    "def process(img):\n",
    "    return resize(img.to(torch.float32).transpose(-1,-3).transpose(-1,-2) / 256)\n",
    "\n",
    "tensor_to_PIL = ToPILImage()\n",
    "\n",
    "softmax = torch.nn.Softmax()\n",
    "def compute_accuracy(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    num_batches, size, test_loss, correct = 0, 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            num_batches += 1\n",
    "            if num_batches >= 10:\n",
    "                break\n",
    "            X, y = data['image'], data['label']\n",
    "            size += X.shape[0]\n",
    "            X = process(X)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            pred = softmax(pred)\n",
    "            correct += torch.all(((pred > 0.5) == y), dim=1).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    return correct, test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1: Train Noise Conditional Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Classifier\n",
    "optim = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "with tqdm(total=N_EPOCHS) as pbar:\n",
    "    for epoch in range(N_EPOCHS):\n",
    "\n",
    "        accuracy, loss = compute_accuracy(dataloader, model, loss_fn)\n",
    "        pbar.set_description(f\"accuracy {accuracy} loss {loss}\")\n",
    "        pbar.refresh()\n",
    "\n",
    "        for i, data in enumerate(dataloader):\n",
    "            inputs, labels = data['image'], data['label']\n",
    "            if i > 10:\n",
    "                break\n",
    "            # Preprocess image\n",
    "            inputs = process(inputs)\n",
    "#             inputs = inputs.unsqueeze(1)\n",
    "                # Add noise for conditioning\n",
    "            # inputs = unconditional_scheduler.add_noise(\n",
    "            #     original_samples=inputs,\n",
    "            #     noise=None,\n",
    "            #     timesteps=torch.randint(\n",
    "            #         low=0,\n",
    "            #         high=len(unconditional_scheduler.discrete_sigmas) // 5,\n",
    "            #         size= (NOISE_BATCH, )\n",
    "            #     ).to(device=DEVICE)\n",
    "            # ).flatten(0,1)\n",
    "\n",
    "            #labels = labels.unsqueeze(0).expand(NOISE_BATCH, *labels.shape).flatten(0,1)\n",
    "            # Training\n",
    "            optim.zero_grad()\n",
    "            predicted = model(inputs)\n",
    "            loss = loss_fn(predicted, labels)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        \n",
    "        # Logging\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoints\n",
    "classifier_name = 'uncon_gender_classifier.pt'\n",
    "\n",
    "#torch.save(model, classifier_name)\n",
    "model = torch.load(classifier_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(dataloader):\n",
    "    eval_inputs, eval_labels = data['image'], data['label']\n",
    "    break\n",
    "eval_inputs = process(inputs)\n",
    "noise = torch.randn_like(eval_inputs)\n",
    "model(noise)\n",
    "tensor_to_PIL(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweedie(x_t, score, sigma):\n",
    "  return x_t + score * sigma**2\n",
    "\n",
    "class NoiselessClassConditionalPipeline(ScoreSdeVePipeline):\n",
    "    def add_conditional_gradient(self, sample, score, sigma, classifier, target, debug=False):\n",
    "        with torch.enable_grad():\n",
    "            sample.requires_grad = True\n",
    "            x_hat = tweedie(sample, score, sigma)\n",
    "            class_probabilities = softmax(classifier(x_hat))\n",
    "            target = class_probabilities[:, target]\n",
    "            torch.log(target).sum().backward()\n",
    "            if debug:\n",
    "                print(target)\n",
    "            score += sample.grad * 5\n",
    "        return score\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def __call__(\n",
    "        self,\n",
    "        classifier,\n",
    "        target: bool = True,\n",
    "        batch_size: int = 1,\n",
    "        num_inference_steps: int = 2000,\n",
    "        generator: Optional[Union[torch.Generator, List[torch.Generator]]] = None,\n",
    "        output_type: Optional[str] = \"pil\",\n",
    "        return_dict: bool = True,\n",
    "        **kwargs,\n",
    "    ) -> Union[ImagePipelineOutput, Tuple]:\n",
    "        img_size = self.unet.config.sample_size\n",
    "        shape = (batch_size, 3, img_size, img_size)\n",
    "\n",
    "        model = self.unet\n",
    "        sample = randn_tensor(shape, generator=generator) * self.scheduler.init_noise_sigma\n",
    "        sample = sample.to(self.device)\n",
    "\n",
    "        self.scheduler.set_timesteps(num_inference_steps)\n",
    "        self.scheduler.set_sigmas(num_inference_steps)\n",
    "\n",
    "        for i, t in enumerate(self.progress_bar(self.scheduler.timesteps)):\n",
    "            sigma_t = self.scheduler.sigmas[i] * torch.ones(shape[0], device=self.device)\n",
    "            std = self.scheduler.sigmas[i]\n",
    "\n",
    "            # correction step\n",
    "            for _ in range(self.scheduler.config.correct_steps):\n",
    "                model_output = self.unet(sample, sigma_t).sample\n",
    "                model_output = self.add_conditional_gradient(sample, model_output, std, classifier, target, debug=i%50==0)\n",
    "                sample = self.scheduler.step_correct(model_output, sample, generator=generator).prev_sample\n",
    "\n",
    "            # prediction step\n",
    "            model_output = model(sample, sigma_t).sample\n",
    "            model_output = self.add_conditional_gradient(sample, model_output, std, classifier, target, debug=i%50==0)\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                x_hat = tweedie(sample, model_output, std)\n",
    "                display(tensor_to_PIL(x_hat[0]))\n",
    "\n",
    "            output = self.scheduler.step_pred(model_output, t, sample, generator=generator)\n",
    "\n",
    "            sample, sample_mean = output.prev_sample, output.prev_sample_mean\n",
    "        \n",
    "        sample = sample_mean.clamp(0, 1)\n",
    "        sample = sample.cpu().permute(0, 2, 3, 1).numpy()\n",
    "        if output_type == \"pil\":\n",
    "            sample = self.numpy_to_pil(sample)\n",
    "\n",
    "        if not return_dict:\n",
    "            return (sample,)\n",
    "\n",
    "        return ImagePipelineOutput(images=sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "\n",
    "conditional_pipeline = NoiselessClassConditionalPipeline(unconditional_pipeline.unet, unconditional_pipeline.scheduler)  \n",
    "images = conditional_pipeline(model, batch_size=9, target=1, num_inference_steps=500).images\n",
    "t = PILToTensor()\n",
    "sample = (t(images[0]) / 256).unsqueeze(0).to(device=DEVICE)\n",
    "print(f\"Predicted: {model(sample).argmax()}\")\n",
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [0,0]\n",
    "for img in images:\n",
    "    sample = (t(img) / 256).unsqueeze(0).to(device=DEVICE)\n",
    "    print(model(sample))\n",
    "    results[model(sample).argmax()] += 1\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank = torch.zeros((3,256,256)).to(device=DEVICE)\n",
    "optim = torch.optim.Adam(params=[blank])\n",
    "\n",
    "print(model(blank.unsqueeze(0)))\n",
    "for i in range(2000):\n",
    "    blank.requires_grad = True\n",
    "    optim.zero_grad()\n",
    "    p = -model(blank.unsqueeze(0))\n",
    "    p[0][1].backward()\n",
    "    optim.step()\n",
    "    blank.requires_grad = False\n",
    "print(model(blank.unsqueeze(0)))\n",
    "blank.grad = None\n",
    "tensor_to_PIL(blank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "std = conditional_pipeline.scheduler.sigmas[400]\n",
    "z = torch.randn_like(blank) * std\n",
    "blank_noised = blank + z\n",
    "print(std)\n",
    "x0 = tweedie(blank_noised, conditional_pipeline.unet(blank_noised.unsqueeze(0), torch.tensor(std)).sample, std)\n",
    "print(model(x0))\n",
    "tensor_to_PIL(x0.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
