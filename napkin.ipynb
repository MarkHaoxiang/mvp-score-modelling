{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from diffusers import ScoreSdeVePipeline, ScoreSdeVeScheduler, UNet2DModel\n",
    "from diffusers.utils.torch_utils import randn_tensor\n",
    "from diffusers.pipelines.pipeline_utils import ImagePipelineOutput\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from torchvision.models import mobilenet_v3_small\n",
    "from torchvision.transforms import Resize, PILToTensor\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from typing import List, Optional, Tuple, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'     # Update this line if you want to use a different device such as TPU or Macbook's MPS\n",
    "PRETRAINED = \"google/ncsnpp-celebahq-256\"\n",
    "DATASET_SOURCE = \"Ryan-sjtu/celebahq-caption\"\n",
    "\n",
    "N_INFERENCE_STEPS = 1000\n",
    "BATCH_SIZE = 32\n",
    "N_EPOCHS = 100\n",
    "NOISE_BATCH = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "unconditional_pipeline = ScoreSdeVePipeline.from_pretrained(PRETRAINED).to(device=DEVICE)\n",
    "unconditional_scheduler: ScoreSdeVeScheduler = unconditional_pipeline.scheduler\n",
    "unet = UNet2DModel.from_pretrained(PRETRAINED)\n",
    "dataset: DatasetDict = load_dataset(DATASET_SOURCE)\n",
    "\n",
    "# Demonstrate unconditional generation\n",
    "    # Also helps to set inference steps\n",
    "example_image = unconditional_pipeline(num_inference_steps=N_INFERENCE_STEPS).images[0]\n",
    "example_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classifer model\n",
    "\n",
    "model = mobilenet_v3_small()\n",
    "model = nn.Sequential(\n",
    "    model.features,\n",
    "    model.avgpool,\n",
    "    nn.Flatten(),\n",
    "    nn.Dropout(0.2, inplace=True),\n",
    "    nn.Linear(in_features=576, out_features=1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# Simple CNN\n",
    "# model = nn.Sequential(\n",
    "#     nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5),\n",
    "#     nn.LeakyReLU(),\n",
    "#     nn.MaxPool2d(kernel_size=5),\n",
    "#     nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5),\n",
    "#     nn.LeakyReLU(),\n",
    "#     nn.MaxPool2d(kernel_size=3),\n",
    "#     nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5),\n",
    "#     nn.LeakyReLU(),\n",
    "#     nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3),\n",
    "#     nn.LazyLinear(out_features=128),\n",
    "#     nn.LeakyReLU(),\n",
    "#     nn.Linear(in_features=128, out_features=1),\n",
    "#     nn.Sigmoid()\n",
    "# )\n",
    "\n",
    "model = model.to(device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct dataloader\n",
    "\n",
    "# Utils\n",
    "def process(img):\n",
    "    return img.to(torch.float32).transpose(-1,-3).transpose(-1,-2) / 256\n",
    "resize = Resize(unconditional_pipeline.unet.config.sample_size)\n",
    "\n",
    "def compute_accuracy(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    num_batches, size, test_loss, correct = 0, 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            num_batches += 1\n",
    "            if num_batches >= 10:\n",
    "                break\n",
    "            X, y = data['image'], data['label']\n",
    "            size += X.shape[0]\n",
    "            X = process(X)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += ((pred > 0.5) == y).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    return correct, test_loss\n",
    "\n",
    "# Dataset\n",
    "train_ds: Dataset = dataset['train'].with_format('torch', device=DEVICE)\n",
    "train_ds = train_ds.map(lambda x: {\n",
    "    'label': \n",
    "        torch.tensor([\n",
    "            1 if process(x['image']).mean() > 0.43 else 0     # Toy Problem\n",
    "#           1 if 'woman' in x['text'] else 0                  # Gender Classification\n",
    "        ],\n",
    "        dtype=torch.float32,\n",
    "        device=DEVICE)\n",
    "        \n",
    "})\n",
    "dataloader = DataLoader(train_ds, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1: Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Classifier\n",
    "optim = torch.optim.Adam(model.parameters())\n",
    "loss_fn = nn.BCELoss()\n",
    "sig = nn.Sigmoid().to(device=DEVICE)\n",
    "\n",
    "with tqdm(total=N_EPOCHS) as pbar:\n",
    "    for epoch in range(N_EPOCHS):\n",
    "\n",
    "        accuracy, loss = compute_accuracy(dataloader, model, loss_fn)\n",
    "        pbar.set_description(f\"accuracy {accuracy} loss {loss}\")\n",
    "        pbar.refresh()\n",
    "\n",
    "        for i, data in enumerate(dataloader):\n",
    "            inputs, labels = data['image'], data['label']\n",
    "\n",
    "            # Preprocess image\n",
    "            inputs = process(inputs)\n",
    "            inputs = resize(inputs).unsqueeze(1)\n",
    "            inputs = unconditional_scheduler.add_noise(\n",
    "                original_samples=inputs,\n",
    "                noise=None,\n",
    "                timesteps=torch.randint(\n",
    "                    low=0,\n",
    "                    high=len(unconditional_scheduler.discrete_sigmas),\n",
    "                    size= (NOISE_BATCH, )\n",
    "                ).to(device=DEVICE)\n",
    "            ).flatten(0,1)\n",
    "            labels = labels.expand(labels.shape[0],NOISE_BATCH).flatten().unsqueeze(-1)\n",
    "            # Training\n",
    "            optim.zero_grad()\n",
    "            predicted = model(inputs)\n",
    "            loss = loss_fn(predicted, labels)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        \n",
    "        # Logging\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoints\n",
    "classifier_name = 'toy_classifier.pt'\n",
    "\n",
    "# torch.save(model, classifier_name)\n",
    "model = torch.load(classifier_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassConditionalScoreSdeVePipeline(ScoreSdeVePipeline):\n",
    "    def add_conditional_gradient(self, sample, output, classifier, target, debug=False):\n",
    "        with torch.enable_grad():\n",
    "            sample.requires_grad = True\n",
    "            predicted = torch.log(classifier(sample))\n",
    "            predicted.sum().backward()\n",
    "            res = sample.grad\n",
    "            if not target:\n",
    "                res = -res\n",
    "            output += res\n",
    "        return output\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def __call__(\n",
    "        self,\n",
    "        classifier,\n",
    "        target: bool = True,\n",
    "        batch_size: int = 1,\n",
    "        num_inference_steps: int = 2000,\n",
    "        generator: Optional[Union[torch.Generator, List[torch.Generator]]] = None,\n",
    "        output_type: Optional[str] = \"pil\",\n",
    "        return_dict: bool = True,\n",
    "        **kwargs,\n",
    "    ) -> Union[ImagePipelineOutput, Tuple]:\n",
    "        img_size = self.unet.config.sample_size\n",
    "        shape = (batch_size, 3, img_size, img_size)\n",
    "\n",
    "        model = self.unet\n",
    "\n",
    "        sample = randn_tensor(shape, generator=generator) * self.scheduler.init_noise_sigma\n",
    "        sample = sample.to(self.device)\n",
    "\n",
    "        self.scheduler.set_timesteps(num_inference_steps)\n",
    "        self.scheduler.set_sigmas(num_inference_steps)\n",
    "\n",
    "        for i, t in enumerate(self.progress_bar(self.scheduler.timesteps)):\n",
    "            sigma_t = self.scheduler.sigmas[i] * torch.ones(shape[0], device=self.device)\n",
    "\n",
    "            # correction step\n",
    "            for _ in range(self.scheduler.config.correct_steps):\n",
    "                model_output = self.unet(sample, sigma_t).sample\n",
    "                model_output = self.add_conditional_gradient(sample, model_output, classifier, target)\n",
    "                sample = self.scheduler.step_correct(model_output, sample, generator=generator).prev_sample\n",
    "\n",
    "            # prediction step\n",
    "            model_output = model(sample, sigma_t).sample\n",
    "            model_output = self.add_conditional_gradient(sample, model_output, classifier, target)\n",
    "            output = self.scheduler.step_pred(model_output, t, sample, generator=generator)\n",
    "\n",
    "            sample, sample_mean = output.prev_sample, output.prev_sample_mean\n",
    "        \n",
    "        sample = sample_mean.clamp(0, 1)\n",
    "        sample = sample.cpu().permute(0, 2, 3, 1).numpy()\n",
    "        if output_type == \"pil\":\n",
    "            sample = self.numpy_to_pil(sample)\n",
    "\n",
    "        if not return_dict:\n",
    "            return (sample,)\n",
    "\n",
    "        return ImagePipelineOutput(images=sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "\n",
    "conditional_pipeline = BinaryClassConditionalScoreSdeVePipeline(unconditional_pipeline.unet, unconditional_pipeline.scheduler)  \n",
    "images = conditional_pipeline(model, batch_size=1, target=False, num_inference_steps=N_INFERENCE_STEPS).images\n",
    "t = PILToTensor()\n",
    "sample = (t(images[0]) / 256).unsqueeze(0).to(device=DEVICE)\n",
    "print(f\"Predicted: {model(sample).item()}\")\n",
    "images[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
