{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from diffusers import ScoreSdeVePipeline, ScoreSdeVeScheduler, UNet2DModel\n",
    "from diffusers.models.unet_2d import UNet2DOutput\n",
    "from diffusers.pipelines.pipeline_utils import ImagePipelineOutput\n",
    "from diffusers.utils import numpy_to_pil\n",
    "from diffusers.utils.torch_utils import randn_tensor\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from torchvision.models import mobilenet_v3_small, MobileNet_V3_Small_Weights\n",
    "from torchvision.transforms import Resize\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from typing import List, Optional, Tuple, Union\n",
    "import torch\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'     # Update this line if you want to use a different device such as TPU or Macbook's MPS\n",
    "PRETRAINED = \"google/ncsnpp-celebahq-256\"\n",
    "DATASET_SOURCE = \"Ryan-sjtu/celebahq-caption\"\n",
    "\n",
    "N_INFERENCE_STEPS = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "unconditional_pipeline = ScoreSdeVePipeline.from_pretrained(PRETRAINED).to(device=DEVICE)\n",
    "unconditional_scheduler: ScoreSdeVeScheduler = unconditional_pipeline.scheduler\n",
    "unet = UNet2DModel.from_pretrained(PRETRAINED)\n",
    "dataset: DatasetDict = load_dataset(DATASET_SOURCE)\n",
    "\n",
    "# Demonstrate unconditional generation\n",
    "    # Also helps to set inference steps\n",
    "# example_image = unconditional_pipeline(num_inference_steps=N_INFERENCE_STEPS).images[0]\n",
    "# example_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Dataset\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "N_EPOCHS = 10\n",
    "\n",
    "model = mobilenet_v3_small()\n",
    "\n",
    "# We use an adjusted mobilenet small for classification\n",
    "model = nn.Sequential(\n",
    "    model.features,\n",
    "    model.avgpool,\n",
    "    nn.Flatten(),\n",
    "    nn.Dropout(0.2, inplace=True),\n",
    "    nn.Linear(in_features=576, out_features=1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "model = model.to(device=DEVICE)\n",
    "\n",
    "# Datase\n",
    "train_ds: Dataset = dataset['train'].with_format('torch', device=DEVICE)\n",
    "\n",
    "train_ds = train_ds.map(lambda x: {\n",
    "    'label': torch.ones(1, device=DEVICE) if 'woman' in x['text'] else torch.zeros(1, device=DEVICE)\n",
    "})\n",
    "dataloader = DataLoader(train_ds, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISE_BATCH = 10 \n",
    "\n",
    "optim = torch.optim.Adam(model.parameters())\n",
    "loss_fn = nn.BCELoss()\n",
    "sig = nn.Sigmoid().to(device=DEVICE)\n",
    "resize = Resize(unconditional_pipeline.unet.config.sample_size)\n",
    "\n",
    "with tqdm(total=N_EPOCHS) as pbar:\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        running_loss = 0\n",
    "        for i, data in enumerate(dataloader):\n",
    "            inputs, labels = data['image'], data['label']\n",
    "\n",
    "            # Preprocess image\n",
    "            inputs = inputs.to(torch.float32).transpose(-1,-3) / 256\n",
    "            inputs = resize(inputs).unsqueeze(1)\n",
    "            inputs = unconditional_scheduler.add_noise(\n",
    "                original_samples=inputs,\n",
    "                noise=None,\n",
    "                timesteps=torch.randint(\n",
    "                    low=0,\n",
    "                    high=len(unconditional_scheduler.discrete_sigmas),\n",
    "                    size= (NOISE_BATCH, )\n",
    "                ).to(device=DEVICE)\n",
    "            ).flatten(0,1)\n",
    "            labels = labels.expand(labels.shape[0],NOISE_BATCH).flatten().unsqueeze(-1)\n",
    "            # Training\n",
    "            optim.zero_grad()\n",
    "            predicted = model(inputs)\n",
    "            loss = loss_fn(predicted, labels)\n",
    "            running_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        \n",
    "        # Logging\n",
    "        pbar.set_description(f\"loss {running_loss}\")\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load classifier\n",
    "torch.save(model, 'gender_classifier.pt')\n",
    "# model = torch.load('gender_classifier.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 0\n",
    "img = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "from diffusers.pipelines.pipeline_utils import ImagePipelineOutput\n",
    "\n",
    "class BinaryClassConditionalScoreSdeVePipeline(ScoreSdeVePipeline):\n",
    "\n",
    "    def add_conditional_gradient(self, sample, output, classifier, target):\n",
    "        with torch.enable_grad():\n",
    "            sample.requires_grad = True\n",
    "            predicted = classifier(sample)\n",
    "            predicted.sum().backward()\n",
    "            res = sample.grad\n",
    "            if not target:\n",
    "                res = -res\n",
    "            output += res\n",
    "        return output\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def __call__(\n",
    "        self,\n",
    "        classifier,\n",
    "        target: bool = True,\n",
    "        batch_size: int = 1,\n",
    "        num_inference_steps: int = 2000,\n",
    "        generator: Optional[Union[torch.Generator, List[torch.Generator]]] = None,\n",
    "        output_type: Optional[str] = \"pil\",\n",
    "        return_dict: bool = True,\n",
    "        **kwargs,\n",
    "    ) -> Union[ImagePipelineOutput, Tuple]:\n",
    "        img_size = self.unet.config.sample_size\n",
    "        shape = (batch_size, 3, img_size, img_size)\n",
    "\n",
    "        model = self.unet\n",
    "\n",
    "        sample = randn_tensor(shape, generator=generator) * self.scheduler.init_noise_sigma\n",
    "        sample = sample.to(self.device)\n",
    "\n",
    "        self.scheduler.set_timesteps(num_inference_steps)\n",
    "        self.scheduler.set_sigmas(num_inference_steps)\n",
    "\n",
    "        for i, t in enumerate(self.progress_bar(self.scheduler.timesteps)):\n",
    "            sigma_t = self.scheduler.sigmas[i] * torch.ones(shape[0], device=self.device)\n",
    "\n",
    "            # correction step\n",
    "            for _ in range(self.scheduler.config.correct_steps):\n",
    "                model_output = self.unet(sample, sigma_t).sample\n",
    "                model_output = self.add_conditional_gradient(sample, model_output, classifier, target)\n",
    "                sample = self.scheduler.step_correct(model_output, sample, generator=generator).prev_sample\n",
    "\n",
    "            # prediction step\n",
    "            model_output = model(sample, sigma_t).sample\n",
    "            model_output = self.add_conditional_gradient(sample, model_output, classifier, target)\n",
    "            output = self.scheduler.step_pred(model_output, t, sample, generator=generator)\n",
    "\n",
    "            sample, sample_mean = output.prev_sample, output.prev_sample_mean\n",
    "        \n",
    "        sample = sample_mean.clamp(0, 1)\n",
    "        sample = sample.cpu().permute(0, 2, 3, 1).numpy()\n",
    "        if output_type == \"pil\":\n",
    "            sample = self.numpy_to_pil(sample)\n",
    "\n",
    "        if not return_dict:\n",
    "            return (sample,)\n",
    "\n",
    "        return ImagePipelineOutput(images=sample)\n",
    "    \n",
    "\n",
    "    \n",
    "conditional_pipeline = BinaryClassConditionalScoreSdeVePipeline(unconditional_pipeline.unet, unconditional_pipeline.scheduler)  \n",
    "images = conditional_pipeline(model, batch_size=9, target=False, num_inference_steps=N_INFERENCE_STEPS).images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[8]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
